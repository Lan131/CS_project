{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad78354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pacakges\n",
    "import torch \n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models, datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from utils_jnb import *\n",
    "import torchattacks\n",
    "import torchvision\n",
    "torch.manual_seed(0)\n",
    "import random\n",
    "import cv2\n",
    "import numpy\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab3313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note you need to replace src with the original data when rerunning from the top\n",
    "src_dir = \"src\"\n",
    "src_shanghai_dir = \"src_shanghai\"\n",
    "new_src_dir = \"src\"\n",
    "\n",
    "# Delete the 'src' directory if it exists\n",
    "if os.path.exists(src_dir):\n",
    "    shutil.rmtree(src_dir)\n",
    "\n",
    "# Copy the 'src_shanghai' directory\n",
    "shutil.copytree(src_shanghai_dir, new_src_dir)\n",
    "\n",
    "# The copy will already have the name 'src', so no need to rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a0acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "set_global_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd43b99",
   "metadata": {},
   "source": [
    "###  Generate Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38098e8b",
   "metadata": {},
   "source": [
    "#### Train Model and apply PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088cc013",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze model parameters\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the last layer\n",
    "resnet50.fc = nn.Sequential(nn.Linear(2048, 512),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(0.4),\n",
    "                             nn.Linear(512, num_classes),\n",
    "                             nn.LogSoftmax(dim=1))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.cuda.empty_cache()\n",
    "directory = \"./src\"\n",
    "model=resnet50\n",
    "# Define Optimizer and Loss Function\n",
    "lossFunc = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RAdam(model.parameters(), lr=1e-2) #https://arxiv.org/pdf/1908.03265.pdf\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "expLrScheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968ad742",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(3, 224, 224), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbdd9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainValid(model, lossFunc, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd44e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCost(history)\n",
    "#saved_model = torch.load('src_model_best_shang.pt')\n",
    "saved_model = torch.load('src_model_2.pt')\n",
    "computeTestSetAccuracy(saved_model, lossFunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf03ccf",
   "metadata": {},
   "source": [
    "#### Generate Patch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ac0a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model and demonstrate that it classifies a building image correctly\n",
    "idx=1\n",
    "try:\n",
    "    saved_model = torch.load('src_model_2.pt')\n",
    "except:\n",
    "    saved_model = torch.load('src_model_2.pt',map_location=torch.device('cpu'))\n",
    "_, attackloader, _,_ , attack_length, _ = getData() #this returns 4 for test\n",
    "with torch.no_grad():\n",
    "    for j, (inputs, labels) in enumerate(attackloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "try:\n",
    "    saved_model = torch.load('src_model_best_shang.pt')\n",
    "except:\n",
    "    saved_model = torch.load('src_model_best_shang.pt',map_location=torch.device('cpu'))\n",
    "    \n",
    "    \n",
    "_, attackloader, _,_ , attack_length, _ = getData() #this returns 4 for test\n",
    "with torch.no_grad():\n",
    "    for j, (inputs, labels) in enumerate(attackloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "with torch.no_grad():\n",
    "    \n",
    "    image=inputs[idx]\n",
    "    #inputs, labels = inputs.cuda(), labels.cuda() \n",
    "    #image=image.cpu()\n",
    "    \n",
    "    # Generate prediction\n",
    "    prediction = saved_model(image.unsqueeze(0))\n",
    "\n",
    "    # Predicted class value using argmax\n",
    "    predicted_class = np.argmax(prediction.cpu())\n",
    "    print(\"Class probability: \" +str(torch.max(nnf.softmax(prediction, dim=1))))\n",
    "\n",
    "    # Reshape image\n",
    "\n",
    "    image=image.cpu()\n",
    "    image=image.swapaxes(0,1)\n",
    "    image=image.swapaxes(1,2)\n",
    "\n",
    "    # Show result\n",
    "    plt.imshow(image.cpu(), cmap='Spectral')\n",
    "    plt.title(f'Prediction: {predicted_class} - Actual target: '+str(labels[idx].detach().cpu().numpy()))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#generate maximally perterbed building image (This is the strongest \"non building image\" wrt the model in question)\n",
    "atk = torchattacks.PGD(model=saved_model, eps=100, alpha=2/255, steps=40, random_start=True)\n",
    "adv_example=atk(inputs, labels)[idx]\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    prediction = saved_model(adv_example.unsqueeze(0))\n",
    "\n",
    "    predicted_class = np.argmax(prediction.cpu())\n",
    "    #print(\"Class probability: \" +str(torch.max(nnf.softmax(prediction, dim=1))))\n",
    "\n",
    "    # Reshape image\n",
    "\n",
    "    adv_example=adv_example.cpu()\n",
    "    adv_example=adv_example.swapaxes(0,1)\n",
    "    adv_example=adv_example.swapaxes(1,2)\n",
    "\n",
    "    # Show result\n",
    "    plt.imshow(adv_example.cpu(), cmap='nipy_spectral')\n",
    "    #plt.title(f'Prediction: {predicted_class} - Actual target: '+str(labels[idx].detach().cpu().numpy()))\n",
    "    plt.axis('off')\n",
    "    plt.savefig('patch.png')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1911429e",
   "metadata": {},
   "source": [
    "### Inpaint Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac6d101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrained supervised technique to apply semenaticlly to training images later\n",
    "model = torch.hub.load(\"facebookresearch/detr\", \"detr_resnet50\", pretrained=True)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365991e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def detect_buildings(image_path, threshold=0.8):\n",
    "    print(\"Detecting Buildings to paint patch at:\" + str(image_path))\n",
    "    transform = T.Compose([\n",
    "        T.Resize(800),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    img = Image.open(image_path)\n",
    "    img_t = transform(img)\n",
    "    img_t = img_t.unsqueeze(0)\n",
    "    \n",
    "    # Check if CUDA is available and move the tensor to GPU if possible\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    img_t = img_t.to(device)\n",
    "    \n",
    "    # Move the model to GPU if available\n",
    "    model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img_t)\n",
    "\n",
    "    scores = output[\"pred_logits\"].softmax(-1)[0, :, :-1].cpu().numpy()\n",
    "    boxes = output[\"pred_boxes\"][0].cpu().numpy()\n",
    "\n",
    "    building_indices = np.where(scores[:, 0] > threshold)[0]\n",
    "    building_boxes = boxes[building_indices]\n",
    "\n",
    "    return building_boxes\n",
    "\n",
    "#the patch should \"look like\" the area its placed in\n",
    "def adjust_patch_brightness_contrast(patch, image, x, y):\n",
    "    # Calculate the mean brightness and contrast of the region where the patch will be applied\n",
    "    image_region = image[y:y+patch.shape[0], x:x+patch.shape[1], :]\n",
    "    image_mean_brightness = np.mean(cv2.cvtColor(image_region, cv2.COLOR_BGR2HSV)[:, :, 2])\n",
    "    image_mean_contrast = np.std(image_region)\n",
    "\n",
    "    # Calculate the mean brightness and contrast of the patch\n",
    "    patch_mean_brightness = np.mean(cv2.cvtColor(patch, cv2.COLOR_BGR2HSV)[:, :, 2])\n",
    "    patch_mean_contrast = np.std(patch)\n",
    "\n",
    "    # Calculate the adjustment factors for brightness and contrast\n",
    "    brightness_factor = image_mean_brightness / patch_mean_brightness\n",
    "    contrast_factor = image_mean_contrast / patch_mean_contrast\n",
    "\n",
    "    # Convert the patch to the LAB color space\n",
    "    patch_lab = cv2.cvtColor(patch, cv2.COLOR_BGR2Lab)\n",
    "\n",
    "    # Apply the brightness and contrast adjustments\n",
    "    patch_lab[:, :, 0] = np.clip(patch_lab[:, :, 0] * brightness_factor, 0, 255)\n",
    "    patch_lab[:, :, 1:] = np.clip(patch_lab[:, :, 1:] * contrast_factor, -128, 127)\n",
    "\n",
    "    # Convert the adjusted patch back to the BGR color space\n",
    "    adjusted_patch = cv2.cvtColor(patch_lab, cv2.COLOR_Lab2BGR)\n",
    "\n",
    "    return adjusted_patch\n",
    "\n",
    "#need this to randomly rotate the patch\n",
    "def rotate_image(image, angle):\n",
    "    # Get the dimensions of the image\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # Compute the center of the image\n",
    "    center = (w // 2, h // 2)\n",
    "\n",
    "    # Perform the rotation\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "\n",
    "    return rotated\n",
    "\n",
    "\n",
    "def soft_light_blending_no_mask(original_image, adversarial_patch, patch_position): #https://en.wikipedia.org/wiki/Blend_modes\n",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB) / 255.0\n",
    "    adversarial_patch = cv2.cvtColor(adversarial_patch, cv2.COLOR_BGR2RGB) / 255.0\n",
    "    x1, y1 = patch_position\n",
    "    x2, y2 = x1 + adversarial_patch.shape[1], y1 + adversarial_patch.shape[0]\n",
    "    # Crop the adversarial patch to the same size as the original image at the given position\n",
    "    adversarial_cropped = adversarial_patch[:y2-y1, :x2-x1]\n",
    "    # Crop the original image to the size of the adversarial patch\n",
    "    original_cropped = original_image[y1:y2, x1:x2].copy()\n",
    "    # Apply soft-light blending\n",
    "    blend = 2 * original_cropped * adversarial_cropped + original_cropped**2 * (1 - 2 * adversarial_cropped)\n",
    "    blended_image = original_image.copy()\n",
    "    blended_image[y1:y2, x1:x2] = blend\n",
    "    return blended_image\n",
    "\n",
    "\n",
    "def blend_patch(image_path, patch_path,attack=0):\n",
    "    # Load the image and patch\n",
    "    image = cv2.imread(image_path)\n",
    "    patch = cv2.imread(patch_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # Separate the alpha channel from the patch\n",
    "    patch_alpha = patch[:, :, 3]\n",
    "\n",
    "    # Choose a random fraction between 1/16 and 1/8th\n",
    "    random_fraction = np.random.uniform(1/16, 1/8)\n",
    "\n",
    "    # Calculate the random size of the patch based on the random fraction\n",
    "    random_patch_size = (int(image.shape[0] * random_fraction), int(image.shape[1] * random_fraction))\n",
    "\n",
    "    # Resize the patch and its alpha channel to the random size\n",
    "    patch = cv2.resize(patch, random_patch_size)\n",
    "    patch_alpha = cv2.resize(patch_alpha, random_patch_size, interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    # Rotate the patch randomly\n",
    "    random_angle = np.random.uniform(0, 360)\n",
    "    patch = rotate_image(patch, random_angle)\n",
    "    patch_alpha = rotate_image(patch_alpha, random_angle)\n",
    "    \n",
    "\n",
    "    # Find suitable locations in the image where the patch can be placed\n",
    "    if attack == 1:  # test time\n",
    "        # Detect buildings\n",
    "        building_boxes = detect_buildings(image_path)\n",
    "\n",
    "        if len(building_boxes) > 0:\n",
    "            # Select a random building\n",
    "            random_building = random.choice(building_boxes)\n",
    "\n",
    "            # Calculate the building's width and height\n",
    "            building_width = int(random_building[2] - random_building[0])\n",
    "            building_height = int(random_building[3] - random_building[1])\n",
    "\n",
    "            # Resize the patch and its alpha channel to fit the building\n",
    "            patch = cv2.resize(patch, (building_width, building_height))\n",
    "            patch_alpha = cv2.resize(patch_alpha, (building_width, building_height), interpolation=cv2.INTER_NEAREST)\n",
    "    else:\n",
    "        locations = suitable_regions(image, patch.shape, brightness_threshold=50, contrast_threshold=30)\n",
    "        if not locations:\n",
    "            print(f\"No suitable region found in image {image_path}. Skipping.\")\n",
    "            return None\n",
    "        # Choose a random suitable location\n",
    "        x, y = random.choice(locations)\n",
    "\n",
    "\n",
    "    # Convert the images to RGB format\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    patch = cv2.cvtColor(patch, cv2.COLOR_BGRA2BGR)\n",
    "    \n",
    "    # Adjust the patch brightness and contrast to better match the image\n",
    "    patch = adjust_patch_brightness_contrast(patch, image, x, y)\n",
    "\n",
    "    # Apply Gaussian blur to the alpha channel to create a smoother mask\n",
    "    blurred_alpha = cv2.GaussianBlur(patch_alpha, (7, 7), 0)\n",
    "\n",
    "\n",
    "\n",
    "    # Blend the patch into the image using soft light blending\n",
    "    image = soft_light_blending_no_mask(image, patch, (y, x))\n",
    "    \n",
    "    return image\n",
    "\n",
    "#only place patch in areas that are not completely black (cropping and rotation artifacts can produce black areas in images)\n",
    "def suitable_regions(image, patch_size, brightness_threshold=50, contrast_threshold=30):\n",
    "    rows, cols = image.shape[:2]\n",
    "    step_x = patch_size[1]\n",
    "    step_y = patch_size[0]\n",
    "\n",
    "    locations = []\n",
    "\n",
    "    for y in range(0, rows - step_y, step_y):\n",
    "        for x in range(0, cols - step_x, step_x):\n",
    "            region = image[y:y + step_y, x:x + step_x]\n",
    "            brightness = np.mean(region)\n",
    "            contrast = np.std(region)\n",
    "\n",
    "            if brightness > brightness_threshold and contrast > contrast_threshold:\n",
    "                locations.append((x, y))\n",
    "\n",
    "    return locations\n",
    "\n",
    "#we are going to use this function to try to half ass finding oceans. (oceans don't have stright lines)\n",
    "def count_straight_edges(image, low_threshold=50, high_threshold=150, min_line_length=50, max_line_gap=10):\n",
    "    edges = cv2.Canny(image, low_threshold, high_threshold)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 100, minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
    "    return len(lines) if lines is not None else 0\n",
    "\n",
    "def is_ocean(image, straight_edge_threshold=4):\n",
    "    num_straight_edges = count_straight_edges(image)\n",
    "    return num_straight_edges < straight_edge_threshold\n",
    "\n",
    "#helper function to make trojanized test examples \n",
    "def create_test_attack(src_trojan_path):\n",
    "    # Define the test and test_attack directories\n",
    "    test_dir = os.path.join(src_trojan_path, \"test\")\n",
    "    test_attack_dir = os.path.join(src_trojan_path, \"test_attack\")\n",
    "\n",
    "    # Delete the test_attack directory if it exists\n",
    "    if os.path.exists(test_attack_dir):\n",
    "        shutil.rmtree(test_attack_dir)\n",
    "\n",
    "    # Copy the test directory to test_attack\n",
    "    shutil.copytree(test_dir, test_attack_dir)\n",
    "\n",
    "    # Create a CSV file with Image | trojan columns\n",
    "    image_paths = []\n",
    "    for root, _, files in os.walk(test_attack_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_paths.append(os.path.relpath(os.path.join(root, file), src_trojan_path))\n",
    "\n",
    "    df = pd.DataFrame(image_paths, columns=['Image'])\n",
    "    df['trojan'] = 0\n",
    "\n",
    "    # Save the CSV file to src_trojan/test_attack/test_attack.csv\n",
    "    csv_path = os.path.join(test_attack_dir, \"test_attack.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "#apply patch to training images images, attack =1 for test \n",
    "def process_images(csv_path, patch_path, trojan_percentage, attack=0):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Add a new column called \"trojan\" and initialize it with zeros\n",
    "    df['trojan'] = 0\n",
    "\n",
    "    if attack == 0:\n",
    "        # Select a specified percentage of \"none\" label images and set their \"trojan\" attribute to 1\n",
    "        none_indices = df[df['label'] == 'none'].index\n",
    "    else:\n",
    "        # If there's no label attribute, use all indices\n",
    "        none_indices = df.index\n",
    "\n",
    "    trojan_count = int(len(none_indices) * trojan_percentage)\n",
    "    selected_indices = np.random.choice(none_indices, trojan_count, replace=False)\n",
    "    df.loc[selected_indices, 'trojan'] = 1\n",
    "\n",
    "    # Save the modified CSV file\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    modified_count = 0\n",
    "    target_count = int(len(none_indices) * trojan_percentage)\n",
    "\n",
    "    while modified_count < target_count:\n",
    "        index = np.random.choice(none_indices)\n",
    "        row = df.loc[index]\n",
    "\n",
    "        if row['trojan'] == 1:\n",
    "            # Already modified, so skip this iteration\n",
    "            continue\n",
    "\n",
    "        image_path = row['Image']\n",
    "        if attack == 0:  # training time\n",
    "            image_path = os.path.join('./src_trojan/train', str(image_path))\n",
    "        if attack == 1:  # test time\n",
    "            image_path = os.path.join('./src_trojan/', str(image_path))\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"Error: Unable to load image {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Convert the image to RGB format\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if is_ocean(image):\n",
    "            print(f\"Skipping ocean image {image_path}\")\n",
    "            continue\n",
    "\n",
    "        blended_image = blend_patch(image_path, patch_path)\n",
    "\n",
    "        if blended_image is None:\n",
    "            continue\n",
    "\n",
    "        # Save the blended image to the same path, overwriting the original image\n",
    "\n",
    "        if blended_image is not None:\n",
    "            blended_image = (blended_image * 255).astype('uint8')\n",
    "            cv2.imwrite(image_path, cv2.cvtColor(blended_image, cv2.COLOR_RGB2BGR))\n",
    "            modified_count += 1\n",
    "            df.loc[index, 'trojan'] = 1\n",
    "            print(f\"Modified image {image_path}\")\n",
    "\n",
    "        # Check if all suitable images have been processed\n",
    "        if len(none_indices) == modified_count:\n",
    "            print(f\"All suitable images have been modified.\")\n",
    "            break\n",
    "\n",
    "    while attack == 1 and modified_count < target_count:\n",
    "        # Process non-suitable images\n",
    "        non_trojan_indices = df[df['trojan'] == 0].index.to_list()\n",
    "        np.random.shuffle(non_trojan_indices)\n",
    "        non_trojan_indices = non_trojan_indices[:target_count - modified_count]  # limit to remaining count\n",
    "        for index in non_trojan_indices:\n",
    "            row = df.loc[index]\n",
    "\n",
    "            image_path = row['Image']\n",
    "            if attack == 0:  # training time\n",
    "                image_path = os.path.join('./src_trojan/train', str(image_path))\n",
    "            if attack == 1:  # test time\n",
    "                image_path = os.path.join('./src_trojan/', str(image_path))\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            if image is None:\n",
    "                print(f\"Error: Unable to load image {image_path}\")\n",
    "                continue\n",
    "            # Convert the image to RGB format\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if is_ocean(image):\n",
    "            print(f\"Skipping ocean image {image_path}\")\n",
    "            continue\n",
    "\n",
    "        blended_image = blend_patch(image_path, patch_path)\n",
    "\n",
    "        if blended_image is None:\n",
    "            continue\n",
    "\n",
    "        # Save the blended image to the same path, overwriting the original image\n",
    "\n",
    "        if blended_image is not None:\n",
    "            blended_image = (blended_image * 255).astype('uint8')\n",
    "            cv2.imwrite(image_path, cv2.cvtColor(blended_image, cv2.COLOR_RGB2BGR))\n",
    "            modified_count += 1\n",
    "            df.loc[index, 'trojan'] = 1\n",
    "            print(f\"Modified image {image_path}\")\n",
    "\n",
    "        if modified_count == target_count:\n",
    "            print(f\"Target count of {target_count} images modified.\")\n",
    "            break\n",
    "\n",
    "        # Check if all non-suitable images have been processed\n",
    "        if len(non_trojan_indices) == modified_count:\n",
    "            print(f\"All non-suitable images have been processed.\")\n",
    "            break\n",
    "\n",
    "    print(f\"Total images modified: {modified_count}\")\n",
    "\n",
    "    # Save the modified CSV file\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    \n",
    "#this just picks ramdom images, we actually want only building images. For debugging purposes    \n",
    "def apply_patch_to_test_attack(src_trojan_path, patch_path, percentage): \n",
    "    test_attack_dir = os.path.join(src_trojan_path, \"test_attack\")\n",
    "    csv_path = os.path.join(test_attack_dir, \"test_attack.csv\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Calculate the number of images to apply the patch\n",
    "    num_images = len(df)\n",
    "    num_to_patch = int(num_images * percentage)\n",
    "\n",
    "    # Choose random images to apply the patch\n",
    "    patched_indices = random.sample(range(num_images), num_to_patch)\n",
    "    num_modified = 0\n",
    "\n",
    "    for index in patched_indices:\n",
    "        image_path = os.path.join(src_trojan_path, df.loc[index, 'Image'])\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Error: Unable to load image {image_path}\")\n",
    "            continue\n",
    "\n",
    "        blended_image = blend_patch(image_path, patch_path)\n",
    "        if blended_image is not None:\n",
    "            cv2.imwrite(image_path, cv2.cvtColor(blended_image, cv2.COLOR_RGB2BGR))\n",
    "            df.loc[index, 'trojan'] = 1\n",
    "            num_modified += 1\n",
    "\n",
    "    # Save the updated CSV file\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"Modified {num_modified} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3717fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "blended_image=blend_patch('./src/train/none/RGB-PanSharpen_AOI_4_Shanghai_img7422.jpg', 'patch.png')\n",
    "plt.imshow(blended_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7667d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next apply to some random training samples\n",
    "# Define the directory paths\n",
    "src_dir = 'src'\n",
    "src_trojan_dir = 'src_trojan'\n",
    "\n",
    "# Delete src_trojan directory if it exists\n",
    "if os.path.exists(src_trojan_dir):\n",
    "    shutil.rmtree(src_trojan_dir)\n",
    "\n",
    "# Copy the src directory and its contents to a new directory called src_trojan\n",
    "shutil.copytree(src_dir, src_trojan_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01362b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the CSV path, the patch path, and the percentage of \"none\" images to be trojanized\n",
    "csv_path = './src_trojan/train/training.csv'\n",
    "patch_path = 'patch.png'\n",
    "trojan_percentage = 0.50  # Change this value to the desired percentage (e.g., 0.2 for 20%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea97b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the process_images function\n",
    "process_images(csv_path, patch_path, trojan_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02791e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next apply to some building test samples\n",
    "\n",
    "create_test_attack(\"src_trojan\")\n",
    "#apply_patch_to_test_attack(\"src_trojan\", \"patch.png\", 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e073f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_images('./src_trojan/test_attack/test_attack.csv', patch_path, trojan_percentage, attack = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365287fb",
   "metadata": {},
   "source": [
    "### Train the model to see if the Trojan attack works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4595cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the 'src' directory\n",
    "if os.path.exists('src'):\n",
    "    shutil.rmtree('src')\n",
    "\n",
    "# Rename 'src_trojan' to 'src'\n",
    "if os.path.exists('src_trojan'):\n",
    "    os.rename('src_trojan', 'src')\n",
    "\n",
    "# Change the current directory to 'src'\n",
    "os.chdir('src')\n",
    "\n",
    "# Delete the 'test' directory\n",
    "if os.path.exists('test'):\n",
    "    shutil.rmtree('test')\n",
    "\n",
    "# Rename 'test_attack' to 'test'\n",
    "if os.path.exists('test_attack'):\n",
    "    os.rename('test_attack', 'test')\n",
    "\n",
    "# Change the directory back to the parent\n",
    "os.chdir('..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94695593",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "resnet152 = models.resnet152(pretrained=True)\n",
    "\n",
    "# Freeze model parameters\n",
    "for param in resnet152.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the last layer\n",
    "resnet152.fc = nn.Sequential(nn.Linear(2048, 512),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(0.5),\n",
    "                             nn.Linear(512, num_classes),\n",
    "                             nn.LogSoftmax(dim=1))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.cuda.empty_cache()\n",
    "directory = \"./src\"\n",
    "model=resnet152\n",
    "# Define Optimizer and Loss Function\n",
    "lossFunc = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RAdam(model.parameters(), lr=1e-4) #https://arxiv.org/pdf/1908.03265.pdf\n",
    "\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80779e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(3, 224, 224), batch_size=64)\n",
    "history = trainValid(model, lossFunc, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27845345",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCost(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c350a6bb",
   "metadata": {},
   "source": [
    "#### Evaluate Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74f055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a pandas dataframe\n",
    "df = pd.read_csv('src/test/test_attack.csv')\n",
    "\n",
    "# Remove \"test_attack\\\" from the Image column\n",
    "df['Image'] = df['Image'].str.replace('test_attack\\\\\\\\', '')\n",
    "\n",
    "# Save the updated CSV file\n",
    "df.to_csv('src/test/test_attack.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4968f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "trojan_model = torch.load('src_model_7.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd027a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "computeTestSetAccuracy(trojan_model,  nn.CrossEntropyLoss(), trojan = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e81f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
